{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a3adef1d",
   "metadata": {},
   "source": [
    "# TP N¬∞1 : Classification des Fleurs Iris\n",
    "## Notebook 2 : Mod√©lisation et √âvaluation\n",
    "\n",
    "**Module** : Introduction √† l'IA et Machine Learning (INFO4111)  \n",
    "**Enseignant** : Dr. St√©phane C.K. TEKOUABOU  \n",
    "**√âtudiant** : [Votre Nom]  \n",
    "**Date** : Janvier 2025\n",
    "\n",
    "---\n",
    "\n",
    "### Objectifs de ce notebook :\n",
    "1. Pr√©parer les donn√©es pour le Machine Learning\n",
    "2. Entra√Æner un mod√®le KNN\n",
    "3. √âvaluer les performances\n",
    "4. Sauvegarder le mod√®le"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1c60771",
   "metadata": {},
   "source": [
    "# TP N¬∞1 : Classification des Fleurs Iris\n",
    "## Notebook 2 : Mod√©lisation et √âvaluation\n",
    "\n",
    "**Module** : Introduction √† l'IA et Machine Learning (INFO4111)  \n",
    "**Enseignant** : Dr. St√©phane C.K. TEKOUABOU  \n",
    "**√âtudiant** : [Votre Nom]  \n",
    "**Date** : Janvier 2025\n",
    "\n",
    "---\n",
    "\n",
    "### Objectifs de ce notebook :\n",
    "1. Pr√©parer les donn√©es pour le Machine Learning\n",
    "2. Entra√Æner un mod√®le KNN\n",
    "3. √âvaluer les performances\n",
    "4. Sauvegarder le mod√®le"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f63e7e49",
   "metadata": {},
   "source": [
    "---\n",
    "## CELLULE 1 : Importations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dab6b1d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importations\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import (accuracy_score, classification_report, \n",
    "                             confusion_matrix, f1_score, precision_score, recall_score)\n",
    "import pickle\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"‚úÖ Biblioth√®ques import√©es avec succ√®s !\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a45573ca",
   "metadata": {},
   "source": [
    "---\n",
    "## √âTAPE 3 : PR√âPARATION DES DONN√âES\n",
    "\n",
    "### CELLULE 2 : Chargement et s√©paration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f088da02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Charger les donn√©es\n",
    "df = pd.read_csv('../data/iris.csv')\n",
    "\n",
    "# S√©parer les caract√©ristiques (X) et la cible (y)\n",
    "X = df.drop('species', axis=1)\n",
    "y = df['species']\n",
    "\n",
    "print(\"Shape de X (caract√©ristiques) :\", X.shape)\n",
    "print(\"Shape de y (cible) :\", y.shape)\n",
    "print(\"\\nR√©partition des classes :\")\n",
    "print(y.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b466a38a",
   "metadata": {},
   "source": [
    "### CELLULE 3 : Division train/test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61275bc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Diviser en ensemble d'entra√Ænement (80%) et de test (20%)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "print(f\"Taille ensemble d'entra√Ænement : {len(X_train)}\")\n",
    "print(f\"Taille ensemble de test : {len(X_test)}\")\n",
    "print(f\"\\nR√©partition train :\")\n",
    "print(y_train.value_counts())\n",
    "print(f\"\\nR√©partition test :\")\n",
    "print(y_test.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf453b08",
   "metadata": {},
   "source": [
    "### CELLULE 4 : Normalisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e5475b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalisation des caract√©ristiques\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "print(\"\\n‚úÖ Donn√©es pr√©par√©es et normalis√©es !\")\n",
    "print(f\"Moyenne apr√®s normalisation : {X_train_scaled.mean():.6f}\")\n",
    "print(f\"√âcart-type apr√®s normalisation : {X_train_scaled.std():.6f}\")\n",
    "\n",
    "# Sauvegarder le scaler\n",
    "with open('../models/scaler.pkl', 'wb') as f:\n",
    "    pickle.dump(scaler, f)\n",
    "print(\"\\n‚úÖ Scaler sauvegard√© dans models/scaler.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6c083e1",
   "metadata": {},
   "source": [
    "---\n",
    "## √âTAPE 4 : ENTRA√éNEMENT DU MOD√àLE KNN\n",
    "\n",
    "### CELLULE 5 : Cr√©ation et entra√Ænement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9a60f90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cr√©er le mod√®le KNN avec k=3 voisins\n",
    "knn = KNeighborsClassifier(n_neighbors=3)\n",
    "\n",
    "# Entra√Æner le mod√®le\n",
    "print(\"üöÄ Entra√Ænement du mod√®le KNN en cours...\")\n",
    "knn.fit(X_train_scaled, y_train)\n",
    "print(\"‚úÖ Mod√®le KNN entra√Æn√© avec succ√®s !\")\n",
    "\n",
    "# Sauvegarder le mod√®le\n",
    "with open('../models/knn_model.pkl', 'wb') as f:\n",
    "    pickle.dump(knn, f)\n",
    "print(\"‚úÖ Mod√®le sauvegard√© dans models/knn_model.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b52bff8e",
   "metadata": {},
   "source": [
    "---\n",
    "## √âTAPE 5 : √âVALUATION DU MOD√àLE\n",
    "\n",
    "### CELLULE 6 : Pr√©dictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22240230",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pr√©dictions sur l'ensemble de test\n",
    "y_pred = knn.predict(X_test_scaled)\n",
    "\n",
    "# Calculer l'exactitude\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"=\" * 60)\n",
    "print(f\"üìä EXACTITUDE DU MOD√àLE KNN : {accuracy * 100:.2f}%\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b5fcc3b",
   "metadata": {},
   "source": [
    "### CELLULE 7 : Rapport de classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26865a4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rapport de classification d√©taill√©\n",
    "print(\"\\nüìã RAPPORT DE CLASSIFICATION :\\n\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# M√©triques suppl√©mentaires\n",
    "precision = precision_score(y_test, y_pred, average='weighted')\n",
    "recall = recall_score(y_test, y_pred, average='weighted')\n",
    "f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "\n",
    "print(f\"\\nüìà M√âTRIQUES SUPPL√âMENTAIRES :\")\n",
    "print(f\"Pr√©cision : {precision * 100:.2f}%\")\n",
    "print(f\"Rappel : {recall * 100:.2f}%\")\n",
    "print(f\"F1-Score : {f1 * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bebe9acf",
   "metadata": {},
   "source": [
    "### CELLULE 8 : Matrice de confusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "765413ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Matrice de confusion\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "print(\"\\nüî¢ MATRICE DE CONFUSION :\\n\")\n",
    "print(conf_matrix)\n",
    "\n",
    "# Visualisation de la matrice de confusion\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(conf_matrix, annot=True, cmap='Blues', fmt='d',\n",
    "            xticklabels=df['species'].unique(), \n",
    "            yticklabels=df['species'].unique(),\n",
    "            cbar_kws={'label': 'Nombre de pr√©dictions'})\n",
    "plt.title('Matrice de Confusion - Mod√®le KNN (k=3)', \n",
    "          fontsize=16, fontweight='bold', pad=20)\n",
    "plt.xlabel('Pr√©dictions', fontsize=12, fontweight='bold')\n",
    "plt.ylabel('Vraies classes', fontsize=12, fontweight='bold')\n",
    "plt.savefig('../visualizations/matrice_confusion_knn.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfaa6e31",
   "metadata": {},
   "source": [
    "---\n",
    "## √âTAPE 6 : INTERPR√âTATION DES R√âSULTATS\n",
    "\n",
    "### CELLULE 9 : Analyse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "647ebead",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"üîç ANALYSE ET INTERPR√âTATION DES R√âSULTATS\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "print(\"\\n1Ô∏è‚É£ ANALYSE DE LA MATRICE DE CONFUSION :\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "# Analyser la matrice de confusion\n",
    "species_list = sorted(df['species'].unique())\n",
    "for i, species in enumerate(species_list):\n",
    "    correct = conf_matrix[i, i]\n",
    "    total = conf_matrix[i].sum()\n",
    "    print(f\"   ‚Ä¢ {species.capitalize():12} : {correct}/{total} correctement class√©es ({correct/total*100:.1f}%)\")\n",
    "    \n",
    "    # Identifier les erreurs\n",
    "    errors = []\n",
    "    for j, other_species in enumerate(species_list):\n",
    "        if i != j and conf_matrix[i, j] > 0:\n",
    "            errors.append(f\"{conf_matrix[i, j]} class√©e(s) comme {other_species}\")\n",
    "    \n",
    "    if errors:\n",
    "        print(f\"     Erreurs : {', '.join(errors)}\")\n",
    "\n",
    "print(\"\\n2Ô∏è‚É£ IMPACT DE LA NORMALISATION :\")\n",
    "print(\"-\" * 80)\n",
    "print(\"   ‚Ä¢ La normalisation StandardScaler centre les donn√©es (moyenne=0, √©cart-type=1)\")\n",
    "print(\"   ‚Ä¢ Cela permet au KNN de calculer des distances √©quitables entre les caract√©ristiques\")\n",
    "print(\"   ‚Ä¢ Sans normalisation, les variables avec de grandes valeurs domineraient le calcul\")\n",
    "print(\"   ‚Ä¢ R√©sultat : am√©lioration significative des performances du mod√®le\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23beaefb",
   "metadata": {},
   "source": [
    "### CELLULE 10 : Test sur de nouveaux exemples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99d2190d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tester le mod√®le sur de nouveaux exemples\n",
    "print(\"\\n3Ô∏è‚É£ TEST SUR DE NOUVEAUX EXEMPLES :\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "# Exemple 1 : Setosa typique\n",
    "exemple_setosa = [[5.1, 3.5, 1.4, 0.2]]\n",
    "exemple_setosa_scaled = scaler.transform(exemple_setosa)\n",
    "pred_setosa = knn.predict(exemple_setosa_scaled)[0]\n",
    "print(f\"\\nExemple Setosa : {exemple_setosa[0]}\")\n",
    "print(f\"Pr√©diction : {pred_setosa}\")\n",
    "\n",
    "# Exemple 2 : Versicolor typique\n",
    "exemple_versicolor = [[5.9, 3.0, 4.2, 1.5]]\n",
    "exemple_versicolor_scaled = scaler.transform(exemple_versicolor)\n",
    "pred_versicolor = knn.predict(exemple_versicolor_scaled)[0]\n",
    "print(f\"\\nExemple Versicolor : {exemple_versicolor[0]}\")\n",
    "print(f\"Pr√©diction : {pred_versicolor}\")\n",
    "\n",
    "# Exemple 3 : Virginica typique\n",
    "exemple_virginica = [[6.5, 3.0, 5.5, 1.8]]\n",
    "exemple_virginica_scaled = scaler.transform(exemple_virginica)\n",
    "pred_virginica = knn.predict(exemple_virginica_scaled)[0]\n",
    "print(f\"\\nExemple Virginica : {exemple_virginica[0]}\")\n",
    "print(f\"Pr√©diction : {pred_virginica}\")\n",
    "\n",
    "print(\"\\n‚úÖ Le mod√®le pr√©dit correctement toutes les esp√®ces types !\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81fa97d2",
   "metadata": {},
   "source": [
    "---\n",
    "## üìä R√âSUM√â DU NOTEBOOK\n",
    "\n",
    "### Ce que nous avons accompli :\n",
    "\n",
    "1. ‚úÖ **Pr√©paration des donn√©es**\n",
    "   - S√©paration X et y\n",
    "   - Division train/test (80/20)\n",
    "   - Normalisation avec StandardScaler\n",
    "\n",
    "2. ‚úÖ **Entra√Ænement du mod√®le**\n",
    "   - Mod√®le : K-Nearest Neighbors (k=3)\n",
    "   - Entra√Ænement sur 120 √©chantillons\n",
    "   - Sauvegarde du mod√®le et du scaler\n",
    "\n",
    "3. ‚úÖ **√âvaluation**\n",
    "   - Test sur 30 √©chantillons\n",
    "   - Calcul des m√©triques (accuracy, precision, recall, F1)\n",
    "   - Matrice de confusion visualis√©e\n",
    "\n",
    "4. ‚úÖ **Interpr√©tation**\n",
    "   - Analyse des erreurs\n",
    "   - Compr√©hension de l'impact de la normalisation\n",
    "   - Tests sur nouveaux exemples\n",
    "\n",
    "### üöÄ Prochaine √©tape :\n",
    "Notebook 3 : Optimisation et comparaison avec d'autres mod√®les\n",
    "\n",
    "**Date de r√©alisation** : Janvier 2025  \n",
    "**Module** : INFO4111  \n",
    "**√âtudiant** : [Votre Nom]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf7427b7",
   "metadata": {},
   "source": [
    "# TP N¬∞1 : Classification des Fleurs Iris\n",
    "## Notebook 2 : Mod√©lisation et √âvaluation\n",
    "\n",
    "**Module** : Introduction √† l'IA et Machine Learning (INFO4111)  \n",
    "**Enseignant** : Dr. St√©phane C.K. TEKOUABOU  \n",
    "**√âtudiant** : [Votre Nom]  \n",
    "**Date** : Janvier 2025\n",
    "\n",
    "---\n",
    "\n",
    "### Objectifs de ce notebook :\n",
    "1. Pr√©parer les donn√©es pour le Machine Learning\n",
    "2. Entra√Æner un mod√®le KNN\n",
    "3. √âvaluer les performances\n",
    "4. Sauvegarder le mod√®le"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "314e280f",
   "metadata": {},
   "source": [
    "---\n",
    "## CELLULE 1 : Importations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ea6fd99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importations\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import (accuracy_score, classification_report, \n",
    "                             confusion_matrix, f1_score, precision_score, recall_score)\n",
    "import pickle\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"‚úÖ Biblioth√®ques import√©es avec succ√®s !\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e87cf0da",
   "metadata": {},
   "source": [
    "---\n",
    "## √âTAPE 3 : PR√âPARATION DES DONN√âES\n",
    "\n",
    "### CELLULE 2 : Chargement et s√©paration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9db6f5ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Charger les donn√©es\n",
    "df = pd.read_csv('../data/iris.csv')\n",
    "\n",
    "# S√©parer les caract√©ristiques (X) et la cible (y)\n",
    "X = df.drop('species', axis=1)\n",
    "y = df['species']\n",
    "\n",
    "print(\"Shape de X (caract√©ristiques) :\", X.shape)\n",
    "print(\"Shape de y (cible) :\", y.shape)\n",
    "print(\"\\nR√©partition des classes :\")\n",
    "print(y.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89865fe4",
   "metadata": {},
   "source": [
    "### CELLULE 3 : Division train/test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6922acc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Diviser en ensemble d'entra√Ænement (80%) et de test (20%)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "print(f\"Taille ensemble d'entra√Ænement : {len(X_train)}\")\n",
    "print(f\"Taille ensemble de test : {len(X_test)}\")\n",
    "print(f\"\\nR√©partition train :\")\n",
    "print(y_train.value_counts())\n",
    "print(f\"\\nR√©partition test :\")\n",
    "print(y_test.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b329430a",
   "metadata": {},
   "source": [
    "### CELLULE 4 : Normalisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0be01cc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalisation des caract√©ristiques\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "print(\"\\n‚úÖ Donn√©es pr√©par√©es et normalis√©es !\")\n",
    "print(f\"Moyenne apr√®s normalisation : {X_train_scaled.mean():.6f}\")\n",
    "print(f\"√âcart-type apr√®s normalisation : {X_train_scaled.std():.6f}\")\n",
    "\n",
    "# Sauvegarder le scaler\n",
    "with open('../models/scaler.pkl', 'wb') as f:\n",
    "    pickle.dump(scaler, f)\n",
    "print(\"\\n‚úÖ Scaler sauvegard√© dans models/scaler.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be232c54",
   "metadata": {},
   "source": [
    "---\n",
    "## √âTAPE 4 : ENTRA√éNEMENT DU MOD√àLE KNN\n",
    "\n",
    "### CELLULE 5 : Cr√©ation et entra√Ænement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6189362b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cr√©er le mod√®le KNN avec k=3 voisins\n",
    "knn = KNeighborsClassifier(n_neighbors=3)\n",
    "\n",
    "# Entra√Æner le mod√®le\n",
    "print(\"üöÄ Entra√Ænement du mod√®le KNN en cours...\")\n",
    "knn.fit(X_train_scaled, y_train)\n",
    "print(\"‚úÖ Mod√®le KNN entra√Æn√© avec succ√®s !\")\n",
    "\n",
    "# Sauvegarder le mod√®le\n",
    "with open('../models/knn_model.pkl', 'wb') as f:\n",
    "    pickle.dump(knn, f)\n",
    "print(\"‚úÖ Mod√®le sauvegard√© dans models/knn_model.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0299166f",
   "metadata": {},
   "source": [
    "---\n",
    "## √âTAPE 5 : √âVALUATION DU MOD√àLE\n",
    "\n",
    "### CELLULE 6 : Pr√©dictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e59a52f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pr√©dictions sur l'ensemble de test\n",
    "y_pred = knn.predict(X_test_scaled)\n",
    "\n",
    "# Calculer l'exactitude\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"=\" * 60)\n",
    "print(f\"üìä EXACTITUDE DU MOD√àLE KNN : {accuracy * 100:.2f}%\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0223c18",
   "metadata": {},
   "source": [
    "### CELLULE 7 : Rapport de classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b13f13f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rapport de classification d√©taill√©\n",
    "print(\"\\nüìã RAPPORT DE CLASSIFICATION :\\n\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# M√©triques suppl√©mentaires\n",
    "precision = precision_score(y_test, y_pred, average='weighted')\n",
    "recall = recall_score(y_test, y_pred, average='weighted')\n",
    "f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "\n",
    "print(f\"\\nüìà M√âTRIQUES SUPPL√âMENTAIRES :\")\n",
    "print(f\"Pr√©cision : {precision * 100:.2f}%\")\n",
    "print(f\"Rappel : {recall * 100:.2f}%\")\n",
    "print(f\"F1-Score : {f1 * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5634074d",
   "metadata": {},
   "source": [
    "### CELLULE 8 : Matrice de confusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47c4b89a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Matrice de confusion\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "print(\"\\nüî¢ MATRICE DE CONFUSION :\\n\")\n",
    "print(conf_matrix)\n",
    "\n",
    "# Visualisation de la matrice de confusion\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(conf_matrix, annot=True, cmap='Blues', fmt='d',\n",
    "            xticklabels=df['species'].unique(), \n",
    "            yticklabels=df['species'].unique(),\n",
    "            cbar_kws={'label': 'Nombre de pr√©dictions'})\n",
    "plt.title('Matrice de Confusion - Mod√®le KNN (k=3)', \n",
    "          fontsize=16, fontweight='bold', pad=20)\n",
    "plt.xlabel('Pr√©dictions', fontsize=12, fontweight='bold')\n",
    "plt.ylabel('Vraies classes', fontsize=12, fontweight='bold')\n",
    "plt.savefig('../visualizations/matrice_confusion_knn.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd633e90",
   "metadata": {},
   "source": [
    "---\n",
    "## √âTAPE 6 : INTERPR√âTATION DES R√âSULTATS\n",
    "\n",
    "### CELLULE 9 : Analyse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7692cfa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"üîç ANALYSE ET INTERPR√âTATION DES R√âSULTATS\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "print(\"\\n1Ô∏è‚É£ ANALYSE DE LA MATRICE DE CONFUSION :\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "# Analyser la matrice de confusion\n",
    "species_list = sorted(df['species'].unique())\n",
    "for i, species in enumerate(species_list):\n",
    "    correct = conf_matrix[i, i]\n",
    "    total = conf_matrix[i].sum()\n",
    "    print(f\"   ‚Ä¢ {species.capitalize():12} : {correct}/{total} correctement class√©es ({correct/total*100:.1f}%)\")\n",
    "    \n",
    "    # Identifier les erreurs\n",
    "    errors = []\n",
    "    for j, other_species in enumerate(species_list):\n",
    "        if i != j and conf_matrix[i, j] > 0:\n",
    "            errors.append(f\"{conf_matrix[i, j]} class√©e(s) comme {other_species}\")\n",
    "    \n",
    "    if errors:\n",
    "        print(f\"     Erreurs : {', '.join(errors)}\")\n",
    "\n",
    "print(\"\\n2Ô∏è‚É£ IMPACT DE LA NORMALISATION :\")\n",
    "print(\"-\" * 80)\n",
    "print(\"   ‚Ä¢ La normalisation StandardScaler centre les donn√©es (moyenne=0, √©cart-type=1)\")\n",
    "print(\"   ‚Ä¢ Cela permet au KNN de calculer des distances √©quitables entre les caract√©ristiques\")\n",
    "print(\"   ‚Ä¢ Sans normalisation, les variables avec de grandes valeurs domineraient le calcul\")\n",
    "print(\"   ‚Ä¢ R√©sultat : am√©lioration significative des performances du mod√®le\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "650c30a5",
   "metadata": {},
   "source": [
    "### CELLULE 10 : Test sur de nouveaux exemples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ff95efb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tester le mod√®le sur de nouveaux exemples\n",
    "print(\"\\n3Ô∏è‚É£ TEST SUR DE NOUVEAUX EXEMPLES :\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "# Exemple 1 : Setosa typique\n",
    "exemple_setosa = [[5.1, 3.5, 1.4, 0.2]]\n",
    "exemple_setosa_scaled = scaler.transform(exemple_setosa)\n",
    "pred_setosa = knn.predict(exemple_setosa_scaled)[0]\n",
    "print(f\"\\nExemple Setosa : {exemple_setosa[0]}\")\n",
    "print(f\"Pr√©diction : {pred_setosa}\")\n",
    "\n",
    "# Exemple 2 : Versicolor typique\n",
    "exemple_versicolor = [[5.9, 3.0, 4.2, 1.5]]\n",
    "exemple_versicolor_scaled = scaler.transform(exemple_versicolor)\n",
    "pred_versicolor = knn.predict(exemple_versicolor_scaled)[0]\n",
    "print(f\"\\nExemple Versicolor : {exemple_versicolor[0]}\")\n",
    "print(f\"Pr√©diction : {pred_versicolor}\")\n",
    "\n",
    "# Exemple 3 : Virginica typique\n",
    "exemple_virginica = [[6.5, 3.0, 5.5, 1.8]]\n",
    "exemple_virginica_scaled = scaler.transform(exemple_virginica)\n",
    "pred_virginica = knn.predict(exemple_virginica_scaled)[0]\n",
    "print(f\"\\nExemple Virginica : {exemple_virginica[0]}\")\n",
    "print(f\"Pr√©diction : {pred_virginica}\")\n",
    "\n",
    "print(\"\\n‚úÖ Le mod√®le pr√©dit correctement toutes les esp√®ces types !\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b298d088",
   "metadata": {},
   "source": [
    "---\n",
    "## üìä R√âSUM√â DU NOTEBOOK\n",
    "\n",
    "### Ce que nous avons accompli :\n",
    "\n",
    "1. ‚úÖ **Pr√©paration des donn√©es**\n",
    "   - S√©paration X et y\n",
    "   - Division train/test (80/20)\n",
    "   - Normalisation avec StandardScaler\n",
    "\n",
    "2. ‚úÖ **Entra√Ænement du mod√®le**\n",
    "   - Mod√®le : K-Nearest Neighbors (k=3)\n",
    "   - Entra√Ænement sur 120 √©chantillons\n",
    "   - Sauvegarde du mod√®le et du scaler\n",
    "\n",
    "3. ‚úÖ **√âvaluation**\n",
    "   - Test sur 30 √©chantillons\n",
    "   - Calcul des m√©triques (accuracy, precision, recall, F1)\n",
    "   - Matrice de confusion visualis√©e\n",
    "\n",
    "4. ‚úÖ **Interpr√©tation**\n",
    "   - Analyse des erreurs\n",
    "   - Compr√©hension de l'impact de la normalisation\n",
    "   - Tests sur nouveaux exemples\n",
    "\n",
    "### üöÄ Prochaine √©tape :\n",
    "Notebook 3 : Optimisation et comparaison avec d'autres mod√®les\n",
    "\n",
    "**Date de r√©alisation** : Janvier 2025  \n",
    "**Module** : INFO4111  \n",
    "**√âtudiant** : [Votre Nom]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c574adeb",
   "metadata": {},
   "source": [
    "---\n",
    "## CELLULE 1 : Importations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e3ac5f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importations\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import (accuracy_score, classification_report, \n",
    "                             confusion_matrix, f1_score, precision_score, recall_score)\n",
    "import pickle\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"‚úÖ Biblioth√®ques import√©es avec succ√®s !\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2b08b0c",
   "metadata": {},
   "source": [
    "---\n",
    "## √âTAPE 3 : PR√âPARATION DES DONN√âES\n",
    "\n",
    "### CELLULE 2 : Chargement et s√©paration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4c48e50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Charger les donn√©es\n",
    "df = pd.read_csv('../data/iris.csv')\n",
    "\n",
    "# S√©parer les caract√©ristiques (X) et la cible (y)\n",
    "X = df.drop('species', axis=1)\n",
    "y = df['species']\n",
    "\n",
    "print(\"Shape de X (caract√©ristiques) :\", X.shape)\n",
    "print(\"Shape de y (cible) :\", y.shape)\n",
    "print(\"\\nR√©partition des classes :\")\n",
    "print(y.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e801d1f",
   "metadata": {},
   "source": [
    "### CELLULE 3 : Division train/test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad628a8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Diviser en ensemble d'entra√Ænement (80%) et de test (20%)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "print(f\"Taille ensemble d'entra√Ænement : {len(X_train)}\")\n",
    "print(f\"Taille ensemble de test : {len(X_test)}\")\n",
    "print(f\"\\nR√©partition train :\")\n",
    "print(y_train.value_counts())\n",
    "print(f\"\\nR√©partition test :\")\n",
    "print(y_test.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d5ebaea",
   "metadata": {},
   "source": [
    "### CELLULE 4 : Normalisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de05724a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalisation des caract√©ristiques\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "print(\"\\n‚úÖ Donn√©es pr√©par√©es et normalis√©es !\")\n",
    "print(f\"Moyenne apr√®s normalisation : {X_train_scaled.mean():.6f}\")\n",
    "print(f\"√âcart-type apr√®s normalisation : {X_train_scaled.std():.6f}\")\n",
    "\n",
    "# Sauvegarder le scaler\n",
    "with open('../models/scaler.pkl', 'wb') as f:\n",
    "    pickle.dump(scaler, f)\n",
    "print(\"\\n‚úÖ Scaler sauvegard√© dans models/scaler.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "574ed022",
   "metadata": {},
   "source": [
    "---\n",
    "## √âTAPE 4 : ENTRA√éNEMENT DU MOD√àLE KNN\n",
    "\n",
    "### CELLULE 5 : Cr√©ation et entra√Ænement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb0064ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cr√©er le mod√®le KNN avec k=3 voisins\n",
    "knn = KNeighborsClassifier(n_neighbors=3)\n",
    "\n",
    "# Entra√Æner le mod√®le\n",
    "print(\"üöÄ Entra√Ænement du mod√®le KNN en cours...\")\n",
    "knn.fit(X_train_scaled, y_train)\n",
    "print(\"‚úÖ Mod√®le KNN entra√Æn√© avec succ√®s !\")\n",
    "\n",
    "# Sauvegarder le mod√®le\n",
    "with open('../models/knn_model.pkl', 'wb') as f:\n",
    "    pickle.dump(knn, f)\n",
    "print(\"‚úÖ Mod√®le sauvegard√© dans models/knn_model.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "410db7e7",
   "metadata": {},
   "source": [
    "---\n",
    "## √âTAPE 5 : √âVALUATION DU MOD√àLE\n",
    "\n",
    "### CELLULE 6 : Pr√©dictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeb7ef14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pr√©dictions sur l'ensemble de test\n",
    "y_pred = knn.predict(X_test_scaled)\n",
    "\n",
    "# Calculer l'exactitude\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"=\" * 60)\n",
    "print(f\"üìä EXACTITUDE DU MOD√àLE KNN : {accuracy * 100:.2f}%\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2a523f1",
   "metadata": {},
   "source": [
    "### CELLULE 7 : Rapport de classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c61e65b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rapport de classification d√©taill√©\n",
    "print(\"\\nüìã RAPPORT DE CLASSIFICATION :\\n\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# M√©triques suppl√©mentaires\n",
    "precision = precision_score(y_test, y_pred, average='weighted')\n",
    "recall = recall_score(y_test, y_pred, average='weighted')\n",
    "f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "\n",
    "print(f\"\\nüìà M√âTRIQUES SUPPL√âMENTAIRES :\")\n",
    "print(f\"Pr√©cision : {precision * 100:.2f}%\")\n",
    "print(f\"Rappel : {recall * 100:.2f}%\")\n",
    "print(f\"F1-Score : {f1 * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11383eb2",
   "metadata": {},
   "source": [
    "### CELLULE 8 : Matrice de confusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0224234a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Matrice de confusion\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "print(\"\\nüî¢ MATRICE DE CONFUSION :\\n\")\n",
    "print(conf_matrix)\n",
    "\n",
    "# Visualisation de la matrice de confusion\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(conf_matrix, annot=True, cmap='Blues', fmt='d',\n",
    "            xticklabels=df['species'].unique(), \n",
    "            yticklabels=df['species'].unique(),\n",
    "            cbar_kws={'label': 'Nombre de pr√©dictions'})\n",
    "plt.title('Matrice de Confusion - Mod√®le KNN (k=3)', \n",
    "          fontsize=16, fontweight='bold', pad=20)\n",
    "plt.xlabel('Pr√©dictions', fontsize=12, fontweight='bold')\n",
    "plt.ylabel('Vraies classes', fontsize=12, fontweight='bold')\n",
    "plt.savefig('../visualizations/matrice_confusion_knn.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba28050a",
   "metadata": {},
   "source": [
    "---\n",
    "## √âTAPE 6 : INTERPR√âTATION DES R√âSULTATS\n",
    "\n",
    "### CELLULE 9 : Analyse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3495657",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"üîç ANALYSE ET INTERPR√âTATION DES R√âSULTATS\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "print(\"\\n1Ô∏è‚É£ ANALYSE DE LA MATRICE DE CONFUSION :\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "# Analyser la matrice de confusion\n",
    "species_list = sorted(df['species'].unique())\n",
    "for i, species in enumerate(species_list):\n",
    "    correct = conf_matrix[i, i]\n",
    "    total = conf_matrix[i].sum()\n",
    "    print(f\"   ‚Ä¢ {species.capitalize():12} : {correct}/{total} correctement class√©es ({correct/total*100:.1f}%)\")\n",
    "    \n",
    "    # Identifier les erreurs\n",
    "    errors = []\n",
    "    for j, other_species in enumerate(species_list):\n",
    "        if i != j and conf_matrix[i, j] > 0:\n",
    "            errors.append(f\"{conf_matrix[i, j]} class√©e(s) comme {other_species}\")\n",
    "    \n",
    "    if errors:\n",
    "        print(f\"     Erreurs : {', '.join(errors)}\")\n",
    "\n",
    "print(\"\\n2Ô∏è‚É£ IMPACT DE LA NORMALISATION :\")\n",
    "print(\"-\" * 80)\n",
    "print(\"   ‚Ä¢ La normalisation StandardScaler centre les donn√©es (moyenne=0, √©cart-type=1)\")\n",
    "print(\"   ‚Ä¢ Cela permet au KNN de calculer des distances √©quitables entre les caract√©ristiques\")\n",
    "print(\"   ‚Ä¢ Sans normalisation, les variables avec de grandes valeurs domineraient le calcul\")\n",
    "print(\"   ‚Ä¢ R√©sultat : am√©lioration significative des performances du mod√®le\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b54097ac",
   "metadata": {},
   "source": [
    "### CELLULE 10 : Test sur de nouveaux exemples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdceb1af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tester le mod√®le sur de nouveaux exemples\n",
    "print(\"\\n3Ô∏è‚É£ TEST SUR DE NOUVEAUX EXEMPLES :\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "# Exemple 1 : Setosa typique\n",
    "exemple_setosa = [[5.1, 3.5, 1.4, 0.2]]\n",
    "exemple_setosa_scaled = scaler.transform(exemple_setosa)\n",
    "pred_setosa = knn.predict(exemple_setosa_scaled)[0]\n",
    "print(f\"\\nExemple Setosa : {exemple_setosa[0]}\")\n",
    "print(f\"Pr√©diction : {pred_setosa}\")\n",
    "\n",
    "# Exemple 2 : Versicolor typique\n",
    "exemple_versicolor = [[5.9, 3.0, 4.2, 1.5]]\n",
    "exemple_versicolor_scaled = scaler.transform(exemple_versicolor)\n",
    "pred_versicolor = knn.predict(exemple_versicolor_scaled)[0]\n",
    "print(f\"\\nExemple Versicolor : {exemple_versicolor[0]}\")\n",
    "print(f\"Pr√©diction : {pred_versicolor}\")\n",
    "\n",
    "# Exemple 3 : Virginica typique\n",
    "exemple_virginica = [[6.5, 3.0, 5.5, 1.8]]\n",
    "exemple_virginica_scaled = scaler.transform(exemple_virginica)\n",
    "pred_virginica = knn.predict(exemple_virginica_scaled)[0]\n",
    "print(f\"\\nExemple Virginica : {exemple_virginica[0]}\")\n",
    "print(f\"Pr√©diction : {pred_virginica}\")\n",
    "\n",
    "print(\"\\n‚úÖ Le mod√®le pr√©dit correctement toutes les esp√®ces types !\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2516a23",
   "metadata": {},
   "source": [
    "---\n",
    "## üìä R√âSUM√â DU NOTEBOOK\n",
    "\n",
    "### Ce que nous avons accompli :\n",
    "\n",
    "1. ‚úÖ **Pr√©paration des donn√©es**\n",
    "   - S√©paration X et y\n",
    "   - Division train/test (80/20)\n",
    "   - Normalisation avec StandardScaler\n",
    "\n",
    "2. ‚úÖ **Entra√Ænement du mod√®le**\n",
    "   - Mod√®le : K-Nearest Neighbors (k=3)\n",
    "   - Entra√Ænement sur 120 √©chantillons\n",
    "   - Sauvegarde du mod√®le et du scaler\n",
    "\n",
    "3. ‚úÖ **√âvaluation**\n",
    "   - Test sur 30 √©chantillons\n",
    "   - Calcul des m√©triques (accuracy, precision, recall, F1)\n",
    "   - Matrice de confusion visualis√©e\n",
    "\n",
    "4. ‚úÖ **Interpr√©tation**\n",
    "   - Analyse des erreurs\n",
    "   - Compr√©hension de l'impact de la normalisation\n",
    "   - Tests sur nouveaux exemples\n",
    "\n",
    "### üöÄ Prochaine √©tape :\n",
    "Notebook 3 : Optimisation et comparaison avec d'autres mod√®les\n",
    "\n",
    "**Date de r√©alisation** : Janvier 2025  \n",
    "**Module** : INFO4111  \n",
    "**√âtudiant** : [Votre Nom]"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
