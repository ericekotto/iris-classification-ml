# ğŸŒ¸ Projet Classification des Fleurs Iris

## ğŸ“‹ Table des matiÃ¨res
- [PrÃ©sentation](#prÃ©sentation)
- [Structure du projet](#structure-du-projet)
- [Installation](#installation)
- [Utilisation](#utilisation)
- [Exercices](#exercices)
- [DÃ©ploiement](#dÃ©ploiement)
- [Tests](#tests)
- [Auteur](#auteur)

---

## ğŸ“– PrÃ©sentation

Ce projet est rÃ©alisÃ© dans le cadre du module **Introduction Ã  l'IA et Machine Learning (INFO4111)** de l'Ã‰cole Normale SupÃ©rieure de YaoundÃ©.

### Objectifs du TP
1. âœ… Familiarisation avec Python pour la data science
2. âœ… Utilisation des bibliothÃ¨ques de ML (scikit-learn, pandas, numpy)
3. âœ… Exploration et visualisation de donnÃ©es
4. âœ… CrÃ©ation et entraÃ®nement de modÃ¨les de classification
5. âœ… Ã‰valuation des performances
6. âœ… DÃ©ploiement avec Flask et Streamlit

### Dataset
Le dataset **Iris** contient 150 Ã©chantillons de fleurs iris rÃ©partis en 3 espÃ¨ces :
- ğŸŒº **Iris Setosa**
- ğŸŒ· **Iris Versicolor**
- ğŸŒ¸ **Iris Virginica**

Chaque Ã©chantillon possÃ¨de 4 caractÃ©ristiques :
- Longueur du sÃ©pale (cm)
- Largeur du sÃ©pale (cm)
- Longueur du pÃ©tale (cm)
- Largeur du pÃ©tale (cm)

---

## ğŸ“ Structure du projet

```
iris_classification_project/
â”‚
â”œâ”€â”€ data/
â”‚   â””â”€â”€ iris.csv                          # Dataset
â”‚
â”œâ”€â”€ notebooks/
â”‚   â”œâ”€â”€ 01_exploration_donnees.ipynb      # Exercices 1-5
â”‚   â”œâ”€â”€ 02_modelisation.ipynb             # Ã‰tapes 3-6
â”‚   â””â”€â”€ 03_optimisation.ipynb             # Ã‰tape 7
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ data_processing.py
â”‚   â”œâ”€â”€ model_training.py
â”‚   â”œâ”€â”€ visualization.py
â”‚   â””â”€â”€ utils.py
â”‚
â”œâ”€â”€ models/
â”‚   â”œâ”€â”€ knn_model.pkl                     # ModÃ¨le KNN
â”‚   â”œâ”€â”€ scaler.pkl                        # Scaler
â”‚   â”œâ”€â”€ best_model.pkl                    # Meilleur modÃ¨le
â”‚   â””â”€â”€ models_comparison.csv             # Comparaison
â”‚
â”œâ”€â”€ flask_app/
â”‚   â””â”€â”€ app.py                            # API Flask
â”‚
â”œâ”€â”€ streamlit_app/
â”‚   â””â”€â”€ dashboard.py                      # Dashboard
â”‚
â”œâ”€â”€ visualizations/                       # Graphiques sauvegardÃ©s
â”‚
â”œâ”€â”€ test_api.py                           # Tests de l'API
â”œâ”€â”€ requirements.txt                      # DÃ©pendances
â””â”€â”€ README.md                             # Ce fichier
```

---

## ğŸ”§ Installation

### PrÃ©requis
- **Python 3.8+** installÃ©
- **Anaconda** (recommandÃ©) ou environnement virtuel Python
- **VS Code** avec extension Python et Jupyter

### Ã‰tape 1 : Cloner ou crÃ©er le projet

```bash
# CrÃ©er le dossier du projet
mkdir iris_classification_project
cd iris_classification_project
```

### Ã‰tape 2 : CrÃ©er l'environnement virtuel

**Option A : Avec Anaconda (RecommandÃ©)**
```bash
# CrÃ©er l'environnement
conda create -n iris_env python=3.10 -y

# Activer l'environnement
conda activate iris_env
```

**Option B : Avec venv**
```bash
# CrÃ©er l'environnement
python -m venv iris_env

# Activer
# Windows:
iris_env\Scripts\activate
# Mac/Linux:
source iris_env/bin/activate
```

### Ã‰tape 3 : Installer les dÃ©pendances

```bash
pip install -r requirements.txt
```

### Ã‰tape 4 : TÃ©lÃ©charger le dataset

**Option A : TÃ©lÃ©chargement automatique**
```python
# CrÃ©er et exÃ©cuter ce script Python
import pandas as pd
from sklearn.datasets import load_iris

iris = load_iris()
df = pd.DataFrame(iris.data, columns=iris.feature_names)
df['species'] = iris.target
df['species'] = df['species'].map({0: 'setosa', 1: 'versicolor', 2: 'virginica'})
df.columns = ['sepal_length', 'sepal_width', 'petal_length', 'petal_width', 'species']
df.to_csv('data/iris.csv', index=False)
print("âœ… Dataset crÃ©Ã© : data/iris.csv")
```

**Option B : TÃ©lÃ©chargement manuel**
- TÃ©lÃ©charger depuis : https://archive.ics.uci.edu/ml/datasets/iris
- Placer dans `data/iris.csv`

---

## ğŸš€ Utilisation

### 1ï¸âƒ£ Exploration des donnÃ©es (Notebooks)

#### Dans VS Code :
1. Ouvrir VS Code dans le dossier du projet
2. Installer l'extension "Jupyter" de Microsoft
3. CrÃ©er un nouveau notebook ou ouvrir ceux fournis
4. SÃ©lectionner le kernel Python (iris_env)
5. ExÃ©cuter les cellules une par une

#### Dans Jupyter Notebook classique :
```bash
# Lancer Jupyter
jupyter notebook

# Ou Jupyter Lab
jupyter lab
```

### 2ï¸âƒ£ ExÃ©cuter les exercices

Les notebooks sont organisÃ©s par Ã©tapes :

**ğŸ““ Notebook 1 : Exploration (Exercices 1-5)**
- Distribution des espÃ¨ces
- Analyse des variables quantitatives
- Nuages de points
- BoÃ®tes Ã  moustaches
- CorrÃ©lations

**ğŸ““ Notebook 2 : ModÃ©lisation (Ã‰tapes 3-6)**
- PrÃ©paration des donnÃ©es
- EntraÃ®nement du modÃ¨le KNN
- Ã‰valuation des performances
- Matrice de confusion

**ğŸ““ Notebook 3 : Optimisation (Ã‰tape 7)**
- Optimisation des hyperparamÃ¨tres
- Comparaison de diffÃ©rents algorithmes
- SÃ©lection du meilleur modÃ¨le

### 3ï¸âƒ£ Lancer l'API Flask

```bash
# Se placer dans le dossier flask_app
cd flask_app

# Lancer le serveur
python app.py
```

L'API sera accessible sur : **http://127.0.0.1:5000**

#### Endpoints disponibles :

| Endpoint | MÃ©thode | Description |
|----------|---------|-------------|
| `/` | GET | Documentation de l'API |
| `/health` | GET | Statut de l'API |
| `/models` | GET | Informations sur les modÃ¨les |
| `/predict` | POST | PrÃ©dire une espÃ¨ce |
| `/predict/batch` | POST | PrÃ©dictions par lot |

#### Exemple de requÃªte :

```bash
curl -X POST http://127.0.0.1:5000/predict \
  -H "Content-Type: application/json" \
  -d '{
    "sepal_length": 5.1,
    "sepal_width": 3.5,
    "petal_length": 1.4,
    "petal_width": 0.2
  }'
```

### 4ï¸âƒ£ Lancer le Dashboard Streamlit

**Dans un nouveau terminal :**

```bash
# Activer l'environnement
conda activate iris_env  # ou source iris_env/bin/activate

# Se placer dans streamlit_app
cd streamlit_app

# Lancer Streamlit
streamlit run dashboard.py
```

Le dashboard sera accessible sur : **http://localhost:8501**

#### FonctionnalitÃ©s du dashboard :
- ğŸ  Page d'accueil avec statistiques
- ğŸ“ˆ Exploration interactive des donnÃ©es
- ğŸ¤– PrÃ©diction en temps rÃ©el
- ğŸ“Š Analyse des performances
- ğŸ” Comparaison des espÃ¨ces

---

## ğŸ“ Exercices

### Exercice 1 : Distribution des espÃ¨ces
- Afficher l'effectif de chaque espÃ¨ce
- CrÃ©er diffÃ©rents types de graphiques
- DÃ©terminer la meilleure reprÃ©sentation

**Code de dÃ©marrage :**
```python
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt

df = pd.read_csv('../data/iris.csv')
print(df['species'].value_counts())

sns.countplot(data=df, x='species')
plt.title('Distribution des espÃ¨ces')
plt.show()
```

### Exercice 2 : Variables quantitatives
- RÃ©sumer chaque variable (moyenne, mÃ©diane, Ã©cart-type)
- CrÃ©er des histogrammes
- Analyser les distributions

### Exercice 3 : Ã‰tude bivariÃ©e
- CrÃ©er des nuages de points
- Analyser les corrÃ©lations
- Identifier les relations entre variables

### Exercice 4 : Boxplots
- Comparer les distributions par espÃ¨ce
- Identifier les outliers
- InterprÃ©ter les diffÃ©rences

### Exercice 5 : CorrÃ©lations
- Calculer la matrice de corrÃ©lation
- CrÃ©er un graphique radar
- Proposer des visualisations avancÃ©es

---

## ğŸ§ª Tests

### Tester l'API Flask

```bash
# Lancer les tests automatiques
python test_api.py
```

Ce script teste :
- âœ… La connexion Ã  l'API
- âœ… Tous les endpoints
- âœ… Les prÃ©dictions pour chaque espÃ¨ce
- âœ… La gestion des erreurs
- âœ… Les prÃ©dictions par lot

### Tests manuels avec Postman

1. **Installer Postman** : https://www.postman.com/downloads/
2. **Importer la collection** (crÃ©er les requÃªtes manuellement)
3. **Tester chaque endpoint**

---

## ğŸ“Š Performances attendues

Avec le modÃ¨le KNN optimisÃ©, vous devriez obtenir :
- **Accuracy** : ~96-98%
- **Precision** : ~96-98%
- **Recall** : ~96-98%
- **F1-Score** : ~96-98%

Les meilleurs modÃ¨les sont gÃ©nÃ©ralement :
1. ğŸ¥‡ SVM (RBF kernel)
2. ğŸ¥ˆ KNN optimisÃ©
3. ğŸ¥‰ Random Forest

---

## ğŸ” DÃ©pannage

### ProblÃ¨me : Le modÃ¨le ne se charge pas
**Solution** :
```bash
# VÃ©rifier que les fichiers existent
ls models/
# Doit afficher : knn_model.pkl, scaler.pkl, best_model.pkl

# RÃ©entraÃ®ner si nÃ©cessaire
# ExÃ©cuter le notebook 02_modelisation.ipynb
```

### ProblÃ¨me : L'API Flask ne dÃ©marre pas
**Solution** :
```bash
# VÃ©rifier l'installation de Flask
pip install flask --upgrade

# VÃ©rifier le port 5000
# Sur Windows :
netstat -an | findstr 5000
# Sur Mac/Linux :
lsof -i :5000

# Tuer le processus si nÃ©cessaire
```

### ProblÃ¨me : Streamlit ne se connecte pas Ã  l'API
**Solution** :
1. VÃ©rifier que Flask est dÃ©marrÃ©
2. VÃ©rifier l'URL dans `dashboard.py` (ligne `API_URL`)
3. Essayer le mode "En local" dans le dashboard

### ProblÃ¨me : Erreur d'import de bibliothÃ¨ques
**Solution** :
```bash
# RÃ©installer toutes les dÃ©pendances
pip install -r requirements.txt --force-reinstall

# Ou installer individuellement
pip install pandas scikit-learn matplotlib seaborn flask streamlit
```

---

## ğŸ“š Ressources supplÃ©mentaires

### Documentation
- [Scikit-learn](https://scikit-learn.org/stable/)
- [Pandas](https://pandas.pydata.org/docs/)
- [Flask](https://flask.palletsprojects.com/)
- [Streamlit](https://docs.streamlit.io/)

### Tutoriels
- [Machine Learning avec Python](https://www.youtube.com/watch?v=7eh4d6sabA0)
- [Flask Tutorial](https://www.youtube.com/watch?v=Z1RJmh_OqeA)
- [Streamlit Tutorial](https://www.youtube.com/watch?v=JwSS70SZdyM)

### Dataset Iris
- [UCI Machine Learning Repository](https://archive.ics.uci.edu/ml/datasets/iris)
- [Article original de R.A. Fisher](https://onlinelibrary.wiley.com/doi/abs/10.1111/j.1469-1809.1936.tb02137.x)

---

## ğŸ‘¨â€ğŸ’» Auteur

**Nom** : Votre Nom  
**Module** : Introduction Ã  l'IA et Machine Learning (INFO4111)  
**Institution** : Ã‰cole Normale SupÃ©rieure de YaoundÃ©  
**AnnÃ©e** : 2024-2025  
**Enseignant** : Dr. StÃ©phane C.K. TEKOUABOU

---

## ğŸ“„ Licence

Ce projet est rÃ©alisÃ© Ã  des fins Ã©ducatives dans le cadre du module INFO4111.

---

## ğŸ™ Remerciements

- Dr. StÃ©phane C.K. TEKOUABOU pour l'encadrement
- UCI Machine Learning Repository pour le dataset
- La communautÃ© open-source Python

---

## ğŸ“ Support

Pour toute question ou problÃ¨me :
1. Consulter la section [DÃ©pannage](#dÃ©pannage)
2. VÃ©rifier les [Issues GitHub](#) (si applicable)
3. Contacter l'enseignant

---

**Bonne chance avec votre TP ! ğŸš€ğŸŒ¸**